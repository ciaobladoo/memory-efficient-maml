{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Checkpointing Model Agnostic Meta Learning\n",
    "\n",
    "We demonstrate how to use memory efficient MAML on CIFAR10.\n",
    "This notebook performs one forward and backward for MAML with a large number of iterations\n",
    "\n",
    "* Data: Random tensors (batch_size, 3, 224, 224)  \n",
    "* Model: ResNet18\n",
    "* Optimizer: SGD with 0.01 learning rate\n",
    "* Batch size: 16\n",
    "* MAML steps: 100 (works with >500 on 11GB GPU)\n",
    "* GPU: whatever colab has to spare, probably K80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "# colab dependencies\n",
    "!pip install torch==1.3.1, torchvision==0.4.2, torch_maml\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "import torch_maml\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# For reproducibility\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmarks = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define compute_loss function and create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interface:\n",
    "# def compute_loss(model, data, **kwargs):\n",
    "#      <YOUR CODE HERE>  # ideally this should be stateless (does not change global variables)\n",
    "#      return loss\n",
    "\n",
    "# Our example\n",
    "def compute_loss(model, data, device='cuda'):\n",
    "    inputs, targets = data\n",
    "    preds = model(inputs.to(device=device))\n",
    "    loss = F.cross_entropy(preds, targets.to(device=device))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model is a torch.nn.Module \n",
    "model = models.resnet18(num_classes=10).to(device)\n",
    "# Optimizer is a custom MAML optimizer, e.g. SGD\n",
    "optimizer = torch_maml.IngraphGradientDescent(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create NaiveMAML and GradientCheckpointingMAML for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficient_maml = torch_maml.GradientCheckpointMAML(\n",
    "    model, compute_loss, optimizer=optimizer, checkpoint_steps=5)\n",
    "\n",
    "naive_maml = torch_maml.NaiveMAML(model, compute_loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity check: small number of steps\n",
    "\n",
    "Both naive and memory-efficient maml should produce the same output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we set such max steps that fits memory for naive MAML to check the implementation\n",
    "maml_steps = 10\n",
    "\n",
    "# Clip meta-learning gradients by global norm to avoid explosion\n",
    "max_grad_grad_norm = 1e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate batch for demonstration. Note that we support using different batches for each MAML step (a-la SGD)\n",
    "x_batch, y_batch = torch.randn((16, 3, 224, 224)), torch.randint(0, 10, (16, ))\n",
    "inputs = [(x_batch, y_batch)] * maml_steps  # use the same batch for each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss naive: 0.5543\n"
     ]
    }
   ],
   "source": [
    "updated_model, loss_history, _ = naive_maml(inputs, loss_kwargs={'device':device},\n",
    "                                            max_grad_grad_norm=max_grad_grad_norm)\n",
    "final_loss = compute_loss(updated_model, (x_batch, y_batch), device=device)\n",
    "final_loss.backward()\n",
    "grads_naive = [params.grad for params in model.parameters()]\n",
    "print(\"Loss naive: %.4f\" % final_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss memory-efficient: 0.5543\n"
     ]
    }
   ],
   "source": [
    "updated_model, loss_history, _ = efficient_maml(inputs, loss_kwargs={'device':device},\n",
    "                                                max_grad_grad_norm=max_grad_grad_norm)\n",
    "final_loss = compute_loss(updated_model, (x_batch, y_batch), device=device)\n",
    "final_loss.backward()\n",
    "grads_efficient = [params.grad for params in model.parameters()]\n",
    "print(\"Loss memory-efficient: %.4f\" % final_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All grads match!\n"
     ]
    }
   ],
   "source": [
    "for grad1, grad2 in zip(grads_naive, grads_efficient):\n",
    "    assert torch.allclose(grad1, grad2)\n",
    "\n",
    "print(\"All grads match!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss RMSProp: 0.0225\n"
     ]
    }
   ],
   "source": [
    "# alternative: use rmsprop optimizer\n",
    "rmsprop_maml = torch_maml.GradientCheckpointMAML(\n",
    "    model, compute_loss, optimizer=torch_maml.IngraphRMSProp(learning_rate=1e-3, beta=0.9, epsilon=1e-5), \n",
    "    checkpoint_steps=5)\n",
    "\n",
    "updated_model, loss_history, _ = rmsprop_maml(inputs, loss_kwargs={'device':device},\n",
    "                                                max_grad_grad_norm=max_grad_grad_norm)\n",
    "final_loss = compute_loss(updated_model, (x_batch, y_batch), device=device)\n",
    "final_loss.backward()\n",
    "grads_efficient = [params.grad for params in model.parameters()]\n",
    "print(\"Loss RMSProp: %.4f\" % final_loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The real meta-learning: 100 steps and beyond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "maml_steps = 100  # feel free to tweak (works with >500)\n",
    "inputs = [(x_batch, y_batch)] * maml_steps\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss memory-efficient: 0.0429\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "updated_model, loss_history, _ = efficient_maml(inputs, loss_kwargs={'device':device},\n",
    "                                        max_grad_grad_norm=max_grad_grad_norm)\n",
    "final_loss = compute_loss(updated_model, (x_batch, y_batch), device=device)\n",
    "final_loss.backward()\n",
    "grads_efficient = [params.grad for params in model.parameters()]\n",
    "\n",
    "plt.plot(loss_history)\n",
    "print(\"Loss memory-efficient: %.4f\" % final_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 14.00 MiB (GPU 0; 10.76 GiB total capacity; 9.67 GiB already allocated; 5.06 MiB free; 231.40 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f8fc96a94a22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# naive maml can't handle this...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m updated_model, loss_history, _ = naive_maml(inputs, loss_kwargs={'device':device},\n\u001b[0;32m----> 3\u001b[0;31m                                             max_grad_grad_norm=max_grad_grad_norm)\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mfinal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdated_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfinal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/memory-efficient-maml/torch_maml/maml.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, opt_kwargs, loss_kwargs, optimizer_state, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mloss_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdated_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mloss_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0mloss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             optimizer_state, updated_model = self.optimizer.step(\n",
      "\u001b[0;32m<ipython-input-2-050e398f6b9f>\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(model, data, device)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py3/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py3/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py3/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1668\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1669\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1670\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1671\u001b[0m     )\n\u001b[1;32m   1672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 14.00 MiB (GPU 0; 10.76 GiB total capacity; 9.67 GiB already allocated; 5.06 MiB free; 231.40 MiB cached)"
     ]
    }
   ],
   "source": [
    "# naive maml can't handle this...\n",
    "updated_model, loss_history, _ = naive_maml(inputs, loss_kwargs={'device':device},\n",
    "                                            max_grad_grad_norm=max_grad_grad_norm)\n",
    "final_loss = compute_loss(updated_model, (x_batch, y_batch), device=device)\n",
    "final_loss.backward()\n",
    "grads_naive = [params.grad for params in model.parameters()]\n",
    "print(\"Loss naive: %.4f\" % final_loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's that simple! Now before you apply it, take a look at \"Tips and Tricks\" section in the README."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
